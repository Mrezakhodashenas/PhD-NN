{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6HiiAfjcTIpU"
      },
      "outputs": [],
      "source": [
        "%reset -f"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOq6G-QBejwM",
        "outputId": "7ea0a673-6669-45a5-d1eb-4c6be9fa928e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czXuC1x8el5J",
        "outputId": "079a5cb0-2cec-47ac-9144-e1b029382383"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.3.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTEDV8wqLZXr",
        "outputId": "05750e2c-438f-4cff-a400-161498ad367c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from snntorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.23.5)\n",
            "Requirement already satisfied: nir in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.0.1)\n",
            "Requirement already satisfied: nirtorch in /usr/local/lib/python3.10/dist-packages (from snntorch) (1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->snntorch) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nir->snntorch) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->snntorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->snntorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGPDVXvjdGsl",
        "outputId": "38366646-5794-4905-d11c-a843d0388036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KehrXuVuPiAt"
      },
      "source": [
        "## set seeds for PyTorch and Numpy to ensure reproducibility:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NbSadcLWPedr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for Python, Numpy, and Torch for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Additional steps if you're using GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UyXSF4IqLFND"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import pickle\n",
        "import matplotlib.animation as animation\n",
        "from scipy.integrate import simps\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import os, sys, time, datetime, json, random\n",
        "import snntorch as snn\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import utils as utls\n",
        "from snntorch import utils\n",
        "from snntorch import surrogate\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import auc\n",
        "from torchsummary import summary\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import torch.nn as nn\n",
        "from scipy.stats import entropy\n",
        "from scipy.special import kl_div\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# import spikeflow as snn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nOyTY0dE50vG"
      },
      "outputs": [],
      "source": [
        "# /////////////////////# Building the Autoencoder\n",
        "#-------------------DataLoaders.  using the MNIST dataset\n",
        "\n",
        "# dataloader arguments\n",
        "batch_size = 250\n",
        "data_path='/data/mnist'\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "# /////////////////////////////////# Define a transform\n",
        "input_size = 32 # resizing the original MNIST from 28 to 32\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "#------------------------------------------- Load MNIST\n",
        "# Training data\n",
        "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Testing data\n",
        "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ha5yn2VjO39Q"
      },
      "outputs": [],
      "source": [
        "# creating directories where we can save the original and reconstructed images for training and testing:\n",
        "# create training/ and testing/ folders in the chosen path\n",
        "if not os.path.isdir('figures/training'):\n",
        "    os.makedirs('figures/training')\n",
        "if not os.path.isdir('figures/binarytraining'):\n",
        "    os.makedirs('figures/binarytraining')\n",
        "\n",
        "if not os.path.isdir('figures/testing'):\n",
        "    os.makedirs('figures/testing')\n",
        "if not os.path.isdir('figures/binarytesting'):\n",
        "    os.makedirs('figures/binarytesting')\n",
        "\n",
        "\n",
        "if not os.path.isdir('Saved_Trained_Checkpoints/'):\n",
        "    os.makedirs('Saved_Trained_Checkpoints/')\n",
        "\n",
        "if not os.path.isdir('Output_Spikes/'):\n",
        "    os.makedirs('Output_Spikes/')\n",
        "\n",
        "if not os.path.isdir('Enc_syn_Spikes/'):\n",
        "    os.makedirs('Enc_syn_Spikes/')\n",
        "\n",
        "\n",
        "if not os.path.isdir('Intermediate_Lyrs/'):\n",
        "    os.makedirs('Intermediate_Lyrs/')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcZMZrCoKFaq",
        "outputId": "1003ad43-dcd7-4626-ba4d-e43d28cfab1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using {torch.cuda.get_device_name()} ({device})\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "                            nn.Conv2d(1, 32, 3,padding = 1,stride=2), # Conv Layer 1\n",
        "                            nn.BatchNorm2d(32),\n",
        "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=thresh),\n",
        "                            nn.Conv2d(32, 64, 3,padding = 1,stride=2), # Conv Layer 2\n",
        "                            nn.BatchNorm2d(64),\n",
        "                            snn.Synaptic(alpha=alpha, beta=beta_syn, spike_grad=spike_grad, init_hidden=True, threshold=thresh), #SNN TORCH LIF NEURON\n",
        "                            nn.Conv2d(64, 128, 3,padding = 1,stride=2), # Conv Layer 3\n",
        "                            nn.BatchNorm2d(128),\n",
        "                            snn.Synaptic(alpha=alpha, beta=beta_syn, spike_grad=spike_grad, init_hidden=True,threshold=thresh), #SNN TORCH LIF NEURON\n",
        "                            nn.Flatten(start_dim = 1, end_dim = 3), #Flatten convolutional output\n",
        "                            nn.Linear(128*4*4, latent_dim), # Fully connected linear layer\n",
        "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True,threshold=thresh)\n",
        "                            )\n",
        "\n",
        "\n",
        "        self.latent_dim = latent_dim #dimensions of the encoded z-space data\n",
        "        self.linearNet= nn.Sequential(\n",
        "                                      nn.Linear(latent_dim,128*4*4),\n",
        "                                      snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True,threshold=thresh))\n",
        "\n",
        "        # Decoder:\n",
        "        self.decoder = nn.Sequential(\n",
        "                            nn.Unflatten(1,(128,4,4)), #Unflatten data from 1 dim to tensor of 128 x 4 x 4\n",
        "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=thresh),\n",
        "                            nn.ConvTranspose2d(128, 64, 3,padding = 1,stride=(2,2),output_padding=1),\n",
        "                            nn.BatchNorm2d(64),\n",
        "                            snn.Synaptic(alpha=alpha, beta=beta_syn, spike_grad=spike_grad, init_hidden=True,threshold=thresh),\n",
        "                            nn.ConvTranspose2d(64, 32, 3,padding = 1,stride=(2,2),output_padding=1),\n",
        "                            nn.BatchNorm2d(32),\n",
        "                            snn.Synaptic(alpha=alpha, beta=beta_syn, spike_grad=spike_grad, init_hidden=True,threshold=thresh),\n",
        "                            nn.ConvTranspose2d(32, 1, 3,padding = 1,stride=(2,2),output_padding=1),\n",
        "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,output=True,threshold=20000) #so membrane can be trained\n",
        "                            )\n",
        "    def forward(self, x):\n",
        "        utils.reset(self.encoder) #need to reset the hidden states of LIF\n",
        "        utils.reset(self.decoder)\n",
        "        utils.reset(self.linearNet)\n",
        "\n",
        "    #-----------------------------encode\n",
        "        spk_mem=[];\n",
        "        spk_rec=[];\n",
        "        spk_rec_syn=[];\n",
        "        encoder_mem=[];\n",
        "        spk_rec_dec=[];\n",
        "        spk_mem_dec=[];\n",
        "        enc5_rec = [];\n",
        "\n",
        "\n",
        "     #------------------------------ intermediate layers\n",
        "\n",
        "        # for step in range(num_steps):\n",
        "        #     enc5 = self.encoder[5](x)             #  enc5 shape: torch.Size([250, 1, 32, 32])\n",
        "        #     enc5_rec.append(enc5)\n",
        "        # enc5_rec = torch.stack(enc5_rec, dim=2)            #   enc5_rec size: torch.Size([250, 1, 5, 32, 32])\n",
        "        # Enc_syn_1 = enc5_rec[:, :, -1]                      # #   torch.Size([250, 1, 32, 32])\n",
        "\n",
        "     #------------------------------ encode\n",
        "        for step in range(num_steps):\n",
        "            spk_x, mem_x = self.encoder(x)              # spk_x size: ([250, 32])  ,   mem_x size: ([250, 32])  , x.shape : torch.Size([250, 1, 32, 32])\n",
        "\n",
        "           #--------------------- Add noise to the membrane potential\n",
        "            mem_x += torch.randn_like(mem_x) * std_dev\n",
        "            # spk_x += torch.randn_like(spk_x) * std_dev\n",
        "\n",
        "            # noise_level = 0.1  # Adjust the noise level\n",
        "            # spike_rate = noise_level * torch.ones_like(spk_x)  # Constant rate for Poisson distribution\n",
        "            # spk_x += torch.poisson(spike_rate)\n",
        "\n",
        "           #---------------------\n",
        "            spk_rec.append(spk_x)\n",
        "            spk_mem.append(mem_x)\n",
        "\n",
        "        spk_rec=torch.stack(spk_rec,dim=2) # stack spikes in second tensor dimension # ----------------spk_rec in torch.stack(spk_rec,dim=2):  torch.Size([250, 32, 5])\n",
        "        spk_mem=torch.stack(spk_mem,dim=2) # stack membranes in second tensor dimension # ----------------spk_mem in torch.stack(spk_mem,dim=2):  torch.Size([250, 32, 5])\n",
        "        out_en = spk_rec[...,step]\n",
        "\n",
        "        # print(\"out_en= spk_rec[...,step]:-----------\" , spk_rec[...,step].size()) # spk_rec[...,step]:----------- torch.Size([250, 32])       input of the latent and then decoder\n",
        "\n",
        "     #------------------------------decode\n",
        "        spk_mem2=[];\n",
        "        spk_rec2=[];\n",
        "        decoded_x=[];\n",
        "        spk_x_dec=[];\n",
        "        mem_x_dec=[];\n",
        "        for step in range(num_steps): #for t in time                           #        from decoder: ([250, 1, 32, 32])\n",
        "            x_recon, x_mem_recon = self.decode(spk_rec[...,step])\n",
        "            spk_rec2.append(x_recon)\n",
        "            spk_mem2.append(x_mem_recon)\n",
        "\n",
        "        spk_rec2=torch.stack(spk_rec2,dim=4)\n",
        "        spk_mem2=torch.stack(spk_mem2,dim=4)\n",
        "\n",
        "        out = spk_mem2[:,:,:,:,-1]\n",
        "\n",
        "        self.out_en = out_en\n",
        "        self.out = out\n",
        "\n",
        "        return out, out_en\n",
        "        # return out, Enc_syn_1\n",
        "\n",
        "    def encode(self,x):\n",
        "      spk_latent_x, mem_latent_x = self.encoder(x)\n",
        "      return spk_latent_x, mem_latent_x\n",
        "\n",
        "\n",
        "    def decode(self,x):\n",
        "        spk_x, mem_x = self.linearNet(x) #convert latent dimension back to total size of features in encoder final layer\n",
        "        spk_x2, mem_x2 = self.decoder(spk_x)\n",
        "        return spk_x2, mem_x2\n",
        "\n"
      ],
      "metadata": {
        "id": "U_D8NuZnxpXG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_pixel_accuracy(real_img, x_recon):\n",
        "    # Flatten the tensors and convert them to NumPy arrays\n",
        "    real_img_np = real_img.flatten().cpu().numpy()\n",
        "    x_recon_np = x_recon.flatten().detach().cpu().numpy()\n",
        "\n",
        "    # Calculate pixel-wise similarity\n",
        "    pixel_accuracy = 1 - np.mean(np.abs(real_img_np - x_recon_np))\n",
        "\n",
        "    return pixel_accuracy\n"
      ],
      "metadata": {
        "id": "9KUjzmarbSvT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5HbcSNNp6vK2"
      },
      "outputs": [],
      "source": [
        "# Training and Testing\n",
        "# using MSE loss to compare the reconstructed image (x_recon) with the original image (real_img)\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "spike_recordings = []\n",
        "train_ber_rec = []\n",
        "test_ber_rec = []\n",
        "threshold_Real = 0.5\n",
        "threshold_Recon = 0.5\n",
        "\n",
        "\n",
        "def train(network, trainloader, opti, epoch):\n",
        "    network=network.train()\n",
        "    train_loss_hist=torch.zeros((1), dtype=dtype, device=device)\n",
        "    train_avg_loss_rec=[]\n",
        "    train_accuracy = []  # Define train_accuracy list\n",
        "\n",
        "    for batch_idx, (real_img, labels) in enumerate(trainloader):\n",
        "        opti.zero_grad()\n",
        "        real_img = real_img.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # -------------Add Gaussian noise to the input images\n",
        "        # real_img = real_img + torch.randn_like(real_img) * std_dev\n",
        "\n",
        "        out, out_en = network(real_img)   # Pass data into network and return reconstructed image and spk_rec\n",
        "        x_recon, out = network(real_img)  # Pass data into network and return reconstructed image and spk_rec.  #  x_recon size torch.Size([250, 1, 32, 32]) ,  # out size torch.Size([250, 32])\n",
        "\n",
        "        # ---------------------------------\n",
        "\n",
        "        #Calculate loss\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "        for step in range(num_steps):\n",
        "          loss_val += F.mse_loss(x_recon, real_img)                  #.view(1, -1)\n",
        "        train_loss_hist += (loss_val.item())/num_steps\n",
        "        avg_loss=train_loss_hist.mean()\n",
        "\n",
        "        # # ---------------------------- Calculate Bit Error Rate (BER)\n",
        "        real_img_binary = (real_img > threshold_Real).float()\n",
        "        x_recon_binary = (x_recon > threshold_Recon).float()\n",
        "        bit_errors = torch.sum(torch.abs(real_img_binary - x_recon_binary))\n",
        "        total_pixels = real_img_binary.numel()  # Total number of pixels in the images\n",
        "        bit_error_rate = bit_errors.item() / total_pixels\n",
        "        train_ber_rec.append(bit_error_rate)  # Append BER to the list\n",
        "\n",
        "        # # --------------------------------- Calculate Accuracy------------\n",
        "        # # # accuracy = accuracy_score(real_img.flatten().cpu().numpy(), x_recon.flatten().detach().cpu().numpy())\n",
        "        train_accuracy_pix = calculate_pixel_accuracy(real_img, x_recon)\n",
        "        train_accuracy.append(train_accuracy_pix.item())\n",
        "\n",
        "         # # -----------------------------------------------------------------\n",
        "        loss_val.backward()\n",
        "        opti.step()\n",
        "        train_loss_rec.append(loss_val.item())\n",
        "# ------------------------------------------------------------------\n",
        "        # Save binary images\n",
        "        Error_bin = (torch.abs(x_recon_binary - real_img_binary))\n",
        "\n",
        "        if batch_idx == len(trainloader)-1:\n",
        "          if epoch in [0, 25, 49]:\n",
        "            utls.save_image(real_img_binary, f'figures/binarytraining/ep{epoch}_inputs_binary.png')\n",
        "            utls.save_image(x_recon_binary, f'figures/binarytraining/ep{epoch}_recon_binary.png')\n",
        "            utls.save_image(Error_bin, f'figures/binarytraining/ep{epoch}_Error_bin.png')\n",
        "\n",
        "\n",
        "        print(f'Train[{epoch}/{max_epoch}][{batch_idx}/{len(trainloader)}] Loss: {loss_val.item():.5f}, ' f'BER: {bit_error_rate:.5f}, Accuracy: {train_accuracy_pix*100:.4f}%')\n",
        "\n",
        "\n",
        "        #Save reconstructed images every at the end of the epoch\n",
        "        if batch_idx == len(trainloader)-1:\n",
        "          if epoch in [0, 10, 25, 49]:\n",
        "            utls.save_image((real_img+1)/2, f'figures/training/epoch{epoch}_finalbatch_inputs.png')\n",
        "            utls.save_image((x_recon+1)/2, f'figures/training/epoch{epoch}_finalbatch_recon.png')\n",
        "            train_auc = auc(np.arange(len(train_loss_rec)), train_loss_rec)\n",
        "\n",
        "\n",
        "    # Compute average accuracy for the entire epoch\n",
        "    epoch_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
        "    print(f'Epoch [{epoch}/{max_epoch}] Average Accuracy: {epoch_accuracy*100:.4f}%')\n",
        "\n",
        "    return loss_val, train_loss_rec, train_accuracy, epoch_accuracy, out, out_en      # train_accuracy, epoch_accuracy, noisy_out_en -----------------added\n",
        "\n",
        "    # return loss_val, train_loss_rec, train_auc , out, out_en, train_accuracy\n",
        "    # return loss_val, train_loss_rec, train_auc , out, out_en  #, spk_rec_batches#, train_avg_loss_rec, #avg_loss #, train_loss_hist\n",
        "    # return loss_val, train_loss_rec, train_auc   #\n",
        "\n",
        "\n",
        "# For Testing, not doing backpropagate, therefore no gradients are required and we use torch.no_grad():\n",
        "#Testing Loop\n",
        "def test(network, testloader, opti, epoch):\n",
        "    network=network.eval()\n",
        "    test_loss_hist=[]\n",
        "    test_avg_loss_rec=[]\n",
        "    test_avg_loss_hist = []\n",
        "    test_accuracy = []  # Define test_accuracy list\n",
        "\n",
        "    spk_rec_test = []\n",
        "    with torch.no_grad(): #no gradient this time\n",
        "        for batch_idx, (real_img, labels) in enumerate(testloader):\n",
        "            real_img = real_img.to(device)#\n",
        "            labels = labels.to(device)\n",
        "            out, out_en = network(real_img)  # Pass data into network and return reconstructed image and spk_rec\n",
        "            x_recon , out = network(real_img)  # Pass data into network and return reconstructed image and spk_rec\n",
        "            #------------------------------------------------------average Loss:\n",
        "            loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "            for step in range(num_steps):\n",
        "              loss_val += F.mse_loss(x_recon, real_img)\n",
        "            avg_loss=loss_val/num_steps\n",
        "            test_loss_hist.append(loss_val.item())\n",
        "          # --------------------------------------------------------BER---\n",
        "            real_img_binary = (real_img > threshold_Real).float()\n",
        "            x_recon_binary = (x_recon > threshold_Recon).float()\n",
        "            bit_errors = torch.sum(torch.abs(real_img_binary - x_recon_binary))\n",
        "            total_pixels = real_img_binary.numel()  # Total number of pixels in the images\n",
        "            bit_error_rate = bit_errors.item() / total_pixels\n",
        "            test_ber_rec.append(bit_error_rate)  # Append BER to the list\n",
        "\n",
        "\n",
        "            # #----------------------------------------------------- Calculate accuracy\n",
        "            # # # accuracy = accuracy_score(real_img.flatten().cpu().numpy(), x_recon.flatten().detach().cpu().numpy())\n",
        "            test_accuracy_pix = calculate_pixel_accuracy(real_img, x_recon)\n",
        "            test_accuracy.append(test_accuracy_pix.item())\n",
        "\n",
        "            # ----------------------------------------------------------------\n",
        "\n",
        "            # Save binary images\n",
        "            Error_bin = (torch.abs(x_recon_binary - real_img_binary))\n",
        "\n",
        "            if batch_idx == len(testloader)-1:\n",
        "              if epoch in [0, 25, 49]:\n",
        "                save_image(real_img_binary, f'figures/binarytesting/ep{epoch}_inputs_binary.png')\n",
        "                save_image(x_recon_binary, f'figures/binarytesting/ep{epoch}_recon_binary.png')\n",
        "                save_image(Error_bin, f'figures/binarytesting/ep{epoch}_Error_bin.png')\n",
        "            # -------------------------------------------------------------------------------------------------\n",
        "\n",
        "            print(f'Test[{epoch}/{max_epoch}][{batch_idx}/{len(testloader)}]  Loss(test): {loss_val.item():.5f}, '  f'BER (test): {bit_error_rate:.5f},  Accuracy(test): {test_accuracy_pix*100:.4f}%')\n",
        "\n",
        "            test_loss_rec.append(loss_val.item())\n",
        "\n",
        "            if batch_idx == len(testloader)-1:\n",
        "              if epoch in [0, 10, 25, 49]:\n",
        "                utls.save_image((real_img+1)/2, f'figures/testing/epoch{epoch}_finalbatch_inputs.png')\n",
        "                utls.save_image((real_img+(torch.randn_like(real_img) * std_dev)+1)/2, f'figures/testing/(real_img+noise)_epoch{epoch}_finalbatch_inputs.png')\n",
        "                utls.save_image((x_recon+1)/2, f'figures/testing/epoch{epoch}_finalbatch_recons.png')\n",
        "                test_auc = auc(np.arange(len(test_loss_rec)), test_loss_rec)\n",
        "\n",
        "\n",
        "    # Compute average accuracy for the entire epoch\n",
        "    epoch_accuracy_test = sum(test_accuracy) / len(test_accuracy)\n",
        "    print(f'Epoch [{epoch}/{max_epoch}] Average Accuracy (test): {epoch_accuracy_test*100:.4f}%')\n",
        "\n",
        "\n",
        "    return loss_val, test_loss_rec, test_accuracy, epoch_accuracy_test, out, out_en     # ------------------------------------- noisy_out_en  , test_accuracy ------------------ADDED\n",
        "    # return loss_val, test_loss_rec, test_auc, out, out_en\n",
        "    # return loss_val, test_loss_rec, test_auc  #\n",
        "\n",
        "for batch_spikes in spike_recordings:\n",
        "    print(batch_spikes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lF2cwM20PKAL"
      },
      "outputs": [],
      "source": [
        "input_size = 32 #resize of mnist data (optional)\n",
        "\n",
        "#setup GPU\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# neuron and simulation parameters\n",
        "spike_grad = surrogate.atan(alpha=2.0)  # alternate surrogate gradient fast_sigmoid(slope=25)\n",
        "\n",
        "train_loss_rec = []\n",
        "test_loss_rec = []\n",
        "train_loss_record = []\n",
        "test_loss_record = []\n",
        "train_avg_loss_rec=[]\n",
        "test_avg_loss_rec=[]\n",
        "\n",
        "  # Synaptic current and membrane potential decay exponentially with rates of alpha and beta\n",
        "alpha=0.9\n",
        "beta_syn=0.0001\n",
        "# beta_syn=0.9\n",
        "beta =0.9\n",
        "\n",
        "std_dev = 0.1  # Adjust this value as needed\n",
        "\n",
        "\n",
        "num_steps=5\n",
        "latent_dim = 32 #dimension of latent layer (how compressed we want the information)\n",
        "thresh=1    #spiking threshold (lower = more spikes are let through)\n",
        "epochs=50\n",
        "# epochs=5\n",
        "max_epoch=epochs\n",
        "\n",
        "  #Define Network and optimizer\n",
        "net=SAE()\n",
        "net = net.to(device)\n",
        "optimizer = torch.optim.AdamW(net.parameters(),\n",
        "                            lr=0.0001,\n",
        "                            betas=(0.9, 0.999),\n",
        "                            weight_decay=0.001)\n",
        "\n",
        "\n",
        "\n",
        "activation = {}\n",
        "# def get_activation(name):\n",
        "#     def hook(model, input, output):\n",
        "#         activation[name] = output.detach()\n",
        "#     return hook\n",
        "\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        if isinstance(output, tuple):\n",
        "            activation[name] = [out.detach() for out in output]\n",
        "        else:\n",
        "            activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "\n",
        "# net.encoder[5].register_forward_hook(get_activation('encoder[5]'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUOjPTrBOjmt",
        "outputId": "8310768f-f8c7-4153-b5c6-8c6af9d8e1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train[0/50][0/240] Loss: 4.57767, BER: 0.13289, Accuracy: 8.8885%\n",
            "Train[0/50][1/240] Loss: 4.57418, BER: 0.13299, Accuracy: 8.9421%\n",
            "Train[0/50][2/240] Loss: 4.55773, BER: 0.13188, Accuracy: 9.0931%\n",
            "Train[0/50][3/240] Loss: 4.54757, BER: 0.13120, Accuracy: 9.1809%\n",
            "Train[0/50][4/240] Loss: 4.54275, BER: 0.13095, Accuracy: 9.2423%\n",
            "Train[0/50][5/240] Loss: 4.56621, BER: 0.13350, Accuracy: 9.0627%\n",
            "Train[0/50][6/240] Loss: 4.55142, BER: 0.13250, Accuracy: 9.2023%\n",
            "Train[0/50][7/240] Loss: 4.44917, BER: 0.12440, Accuracy: 10.0219%\n",
            "Train[0/50][8/240] Loss: 4.48977, BER: 0.12766, Accuracy: 9.7280%\n",
            "Train[0/50][9/240] Loss: 4.56694, BER: 0.13432, Accuracy: 9.1014%\n",
            "Train[0/50][10/240] Loss: 4.48085, BER: 0.12804, Accuracy: 9.8105%\n",
            "Train[0/50][11/240] Loss: 4.50616, BER: 0.13008, Accuracy: 9.6321%\n",
            "Train[0/50][12/240] Loss: 4.55497, BER: 0.13409, Accuracy: 9.2800%\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"Saved_Trained_Checkpoints/\"\n",
        "Output_Spikes = \"Output_Spikes/\"\n",
        "Enc_syn_Spikes = \"Enc_syn_Spikes/\"\n",
        "Intermediate_Lyrs = \"Intermediate_Lyrs/\"\n",
        "epoch_activations_list = [] # Create a list to store activations for each epoch\n",
        "epoch_activations = {}\n",
        "\n",
        "\n",
        "# ///////////////////////////////////\n",
        "\n",
        "# Define hook_layers and hook_names\n",
        "hook_layers = [net.encoder[2], net.encoder[5], net.encoder[8], net.encoder[11], net.decoder[1], net.decoder[4], net.decoder[7], net.decoder[9]]\n",
        "hook_names = [\"Enc_Lk1\", \"Enc_syn1\", \"Enc_syn2\", \"Enc_Lk2\", \"Dec_Lk1\", \"Dec_syn1\", \"Dec_syn2\", \"Dec_Lk2\"]\n",
        "\n",
        "# Create an empty dictionary to store activations\n",
        "epoch_activations = {}\n",
        "\n",
        "# Register hooks for capturing activations\n",
        "hooks = []\n",
        "for i, layer in enumerate(hook_layers):\n",
        "    hook_fn = get_activation(hook_names[i])\n",
        "    hooks.append(layer.register_forward_hook(hook_fn))\n",
        "\n",
        "# Run training and testing\n",
        "for e in range(epochs):\n",
        "    train_loss = train(net, train_loader, optimizer, e)\n",
        "    train_avg_loss_rec.append(sum(train_loss_rec) / len(train_loader))\n",
        "\n",
        "    test_loss = test(net, test_loader, optimizer, e)\n",
        "    test_avg_loss_rec.append(sum(test_loss_rec) / (len(test_loader)))\n",
        "\n",
        "    # # #---------------------------------------------------------- Access the out_en tensor\n",
        "    out_en = net.out_en\n",
        "    out_en_numpy = out_en.cpu().detach().numpy()\n",
        "    # Save with a different name for each epoch\n",
        "    out_en_filename = Output_Spikes + f\"out_en_epoch_{e + 1}.npy\"\n",
        "    np.save(out_en_filename, out_en_numpy)\n",
        "    # # #---------------------------------------------------------- Access the out_en tensor\n",
        "    # noisy_out_en = net.noisy_out_en\n",
        "    # noisy_out_en_numpy = noisy_out_en.cpu().detach().numpy()\n",
        "    # # Save with a different name for each epoch\n",
        "    # noisy_out_en_filename = Output_Spikes + f\"noisy_out_en_epoch_{e + 1}.npy\"\n",
        "    # np.save(noisy_out_en_filename, noisy_out_en_numpy)\n",
        "\n",
        "\n",
        "    # #-----------------------------------------------------------Access the out tensor\n",
        "    out = net.out\n",
        "    out_numpy = out.cpu().detach().numpy()\n",
        "    # Save with a different name for each epoch\n",
        "    out_filename = Output_Spikes + f\"out_epoch_{e + 1}.npy\"\n",
        "    np.save(out_filename, out_numpy)\n",
        "    # -------------------------------------------------------------------- Intermediate Layers\n",
        "# Check if the current epoch is a multiple of 10\n",
        "    if (e + 1) % 10 == 0:\n",
        "        # Save the epoch_activations dictionary to a file\n",
        "        activations_path = Intermediate_Lyrs +  f\"activations_epoch_{e + 1}.pkl\"\n",
        "        with open(activations_path, 'wb') as file:\n",
        "            pickle.dump(epoch_activations, file)\n",
        "    # Capture activations for the current epoch\n",
        "    epoch_activations[e] = {}\n",
        "    for i, name in enumerate(hook_names):\n",
        "        epoch_activations[e][name] = activation.get(name, None)  # Use get to avoid KeyError\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# beta_syn=0.0001\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kIHnS02IKMnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}